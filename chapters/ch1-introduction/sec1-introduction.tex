\chapter{Introduction}\label{ch1:introduction}
 
From pertinent work meetings to casual conversations with family and friends, an ever increasing number of people use video chatting/conferencing applications such as FaceTime, Zoom, Google Meet, and Microsoft Teams, to name a few. One way of improving video chat experience is to bring in a feel of 3D by providing alternate views (images or frames) of each viewed scene, rendered at different viewpoints. To fortify the 3D experience each novel view would have to be rendered at the right angle such that it aligns with the viewpoint of the viewer. This would require taking the viewer's transient head pose\footnote{Pose refers to the combination of any object's position and orientation in 3D world space, including cameras. In contrast, we only use the \textit{orientation} of the viewer's head in the world as the head pose for viewed scenes to be rerendered at.} into account. In this way, we can seek to get an ideal feel of 3D by, essentially, simulating what happens when we move our heads. When we move our heads, what we see in terms of the extent of the foreground, the background, and everything in between changes based on the change in our head poses. These changes need to be reflected in rendered novel views. In this work, we attempt to emulate 3D video chatting via targeted high-quality novel view synthesis.

\input{chapters/ch1-introduction/sec2-motivation}
\input{chapters/ch1-introduction/sec3-contribution}