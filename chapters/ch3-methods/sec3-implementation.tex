\section{Implementation}\label{sec3:implementation} 


please complete richards conversation to glean more details about implementation

Richard Tucker emails about implementation details:

prof ventura:
I think that must be it – I am running it in eager mode.  We will work on switching over.  Thanks again, Richard.


richard:

Our training setup was rather different: we used the old tf Estimator system as we had a configuration to allow us to do distributed training on ten workers.

 

But even on a single worker, our gradient calculation took less than a second. I wonder if maybe you are doing everything in eager mode so there is a lot of overhead? Using keras's model.fit or the old estimator system, or just wrapping things in tf.function, should allow the critical parts to run in graph mode ought to be faster.

Another possibility is things are too big to fit on your GPU. We used a batch size of 4, if I remember correctly.


prof ventura:

Okay, thanks, Richard.  At least I had the right intuition in thinking that might be an issue!

 

We are able to train the model now and the loss does go down which is great.  However, the gradient calculation

 

grads = tape.gradient(loss, model.trainable_weights)

 

takes about one minute!  Is that what you experienced as well?  I am using a batch size of 8 and this is on an Nvidia V100.


richard:




Training details. We implement our system in TensorFlow [Abadi
et al. 2016]. We train the network using the ADAM solver [Kingma
and Ba 2014] for 600K iterations with learning rate 0.0002, β1 =
0.9, β2 = 0.999, and batch size 1. During training, the images and
MPI have a spatial resolution of 1024 × 576, but the model can be
applied to arbitrary resolution at test time in a fully-convolutional
manner. Training takes about one week on a Tesla P100 GPU.

They didn't even use multiGPU

issue happened is the resolution had to be fixed and colmap had to be run again

difference between train.py throws NaN gradient errors np.loadtext thingie and np.generatefromtext thingie such that one possibly inclused empty and the other discards copletely?

training just takes +1 frame to be the target
only testing takes +5 or +10 frames according to the 2020 paper


Expanding upon pipeline description ---

video ------------> input 1 --------------> training
|
|
|-----------------> COLMAP -----------> 3D points per video frame -------------> input 2 -----------> same training

how does data loader work?

Original authors choice with colmap 
my reason for pursuing colmap
what does colmap do> --------> bundle adjustment, triangulation, 

COLMAP highlevel

Triangulation
Bundle Adjustment